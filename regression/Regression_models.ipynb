{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "newborn_train = pd.read_csv('../data/newborn_train_prep.csv')\n",
    "newborn_test = pd.read_csv('../data/newborn_test_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mother_marital_status</th>\n",
       "      <th>mother_height</th>\n",
       "      <th>mother_weight_gain</th>\n",
       "      <th>father_age</th>\n",
       "      <th>father_education</th>\n",
       "      <th>cigarettes_before_pregnancy</th>\n",
       "      <th>prenatal_care_month</th>\n",
       "      <th>number_prenatal_visits</th>\n",
       "      <th>previous_cesarean</th>\n",
       "      <th>newborn_gender</th>\n",
       "      <th>newborn_weight</th>\n",
       "      <th>body_mass_index_to_delivery_weight</th>\n",
       "      <th>mother_race_white</th>\n",
       "      <th>mother_race_black</th>\n",
       "      <th>mother_race_aian</th>\n",
       "      <th>mother_race_asian</th>\n",
       "      <th>mother_race_nhopi</th>\n",
       "      <th>mother_race_more_than_one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.465098</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.353446</td>\n",
       "      <td>-0.405828</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>-0.223724</td>\n",
       "      <td>-0.217339</td>\n",
       "      <td>-0.361500</td>\n",
       "      <td>-0.430785</td>\n",
       "      <td>1.024157</td>\n",
       "      <td>3045</td>\n",
       "      <td>-0.219907</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>-0.40252</td>\n",
       "      <td>-0.094952</td>\n",
       "      <td>-0.252175</td>\n",
       "      <td>-0.054113</td>\n",
       "      <td>-0.154076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.682548</td>\n",
       "      <td>0.675993</td>\n",
       "      <td>-0.053185</td>\n",
       "      <td>0.211499</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>-0.223724</td>\n",
       "      <td>-0.150342</td>\n",
       "      <td>-0.109427</td>\n",
       "      <td>-0.430785</td>\n",
       "      <td>1.024157</td>\n",
       "      <td>3827</td>\n",
       "      <td>-0.002457</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>-0.40252</td>\n",
       "      <td>-0.094952</td>\n",
       "      <td>-0.252175</td>\n",
       "      <td>-0.054113</td>\n",
       "      <td>-0.154076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.682548</td>\n",
       "      <td>-0.071056</td>\n",
       "      <td>-0.663131</td>\n",
       "      <td>-0.714491</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>-0.223724</td>\n",
       "      <td>-0.150342</td>\n",
       "      <td>-0.613573</td>\n",
       "      <td>-0.430785</td>\n",
       "      <td>-0.976412</td>\n",
       "      <td>3997</td>\n",
       "      <td>0.533819</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>-0.40252</td>\n",
       "      <td>-0.094952</td>\n",
       "      <td>-0.252175</td>\n",
       "      <td>-0.054113</td>\n",
       "      <td>-0.154076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.682548</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.827848</td>\n",
       "      <td>-0.405828</td>\n",
       "      <td>2.146529</td>\n",
       "      <td>-0.223724</td>\n",
       "      <td>-0.217339</td>\n",
       "      <td>0.142646</td>\n",
       "      <td>-0.430785</td>\n",
       "      <td>1.024157</td>\n",
       "      <td>3240</td>\n",
       "      <td>-0.787252</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>-0.40252</td>\n",
       "      <td>-0.094952</td>\n",
       "      <td>-0.252175</td>\n",
       "      <td>-0.054113</td>\n",
       "      <td>-0.154076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.465098</td>\n",
       "      <td>-0.071056</td>\n",
       "      <td>1.437794</td>\n",
       "      <td>-0.714491</td>\n",
       "      <td>-0.722169</td>\n",
       "      <td>-0.223724</td>\n",
       "      <td>-0.083344</td>\n",
       "      <td>-0.361500</td>\n",
       "      <td>-0.430785</td>\n",
       "      <td>-0.976412</td>\n",
       "      <td>3544</td>\n",
       "      <td>-0.537870</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>-0.40252</td>\n",
       "      <td>-0.094952</td>\n",
       "      <td>-0.252175</td>\n",
       "      <td>-0.054113</td>\n",
       "      <td>-0.154076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mother_marital_status  mother_height  mother_weight_gain  \\\n",
       "0           0               1.465098       0.302469            0.353446   \n",
       "1           2              -0.682548       0.675993           -0.053185   \n",
       "2           3              -0.682548      -0.071056           -0.663131   \n",
       "3           4              -0.682548       0.302469            0.827848   \n",
       "4           5               1.465098      -0.071056            1.437794   \n",
       "\n",
       "   father_age  father_education  cigarettes_before_pregnancy  \\\n",
       "0   -0.405828          0.999050                    -0.223724   \n",
       "1    0.211499          0.999050                    -0.223724   \n",
       "2   -0.714491          0.999050                    -0.223724   \n",
       "3   -0.405828          2.146529                    -0.223724   \n",
       "4   -0.714491         -0.722169                    -0.223724   \n",
       "\n",
       "   prenatal_care_month  number_prenatal_visits  previous_cesarean  \\\n",
       "0            -0.217339               -0.361500          -0.430785   \n",
       "1            -0.150342               -0.109427          -0.430785   \n",
       "2            -0.150342               -0.613573          -0.430785   \n",
       "3            -0.217339                0.142646          -0.430785   \n",
       "4            -0.083344               -0.361500          -0.430785   \n",
       "\n",
       "   newborn_gender  newborn_weight  body_mass_index_to_delivery_weight  \\\n",
       "0        1.024157            3045                           -0.219907   \n",
       "1        1.024157            3827                           -0.002457   \n",
       "2       -0.976412            3997                            0.533819   \n",
       "3        1.024157            3240                           -0.787252   \n",
       "4       -0.976412            3544                           -0.537870   \n",
       "\n",
       "   mother_race_white  mother_race_black  mother_race_aian  mother_race_asian  \\\n",
       "0           0.553114           -0.40252         -0.094952          -0.252175   \n",
       "1           0.553114           -0.40252         -0.094952          -0.252175   \n",
       "2           0.553114           -0.40252         -0.094952          -0.252175   \n",
       "3           0.553114           -0.40252         -0.094952          -0.252175   \n",
       "4           0.553114           -0.40252         -0.094952          -0.252175   \n",
       "\n",
       "   mother_race_nhopi  mother_race_more_than_one  \n",
       "0          -0.054113                  -0.154076  \n",
       "1          -0.054113                  -0.154076  \n",
       "2          -0.054113                  -0.154076  \n",
       "3          -0.054113                  -0.154076  \n",
       "4          -0.054113                  -0.154076  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newborn_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mother_marital_status</th>\n",
       "      <th>mother_height</th>\n",
       "      <th>mother_weight_gain</th>\n",
       "      <th>father_age</th>\n",
       "      <th>father_education</th>\n",
       "      <th>cigarettes_before_pregnancy</th>\n",
       "      <th>prenatal_care_month</th>\n",
       "      <th>number_prenatal_visits</th>\n",
       "      <th>previous_cesarean</th>\n",
       "      <th>newborn_gender</th>\n",
       "      <th>body_mass_index_to_delivery_weight</th>\n",
       "      <th>mother_race_white</th>\n",
       "      <th>mother_race_black</th>\n",
       "      <th>mother_race_aian</th>\n",
       "      <th>mother_race_asian</th>\n",
       "      <th>mother_race_nhopi</th>\n",
       "      <th>mother_race_more_than_one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.683541</td>\n",
       "      <td>-0.444973</td>\n",
       "      <td>-0.458953</td>\n",
       "      <td>-0.252421</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>-0.222923</td>\n",
       "      <td>-0.216920</td>\n",
       "      <td>0.897192</td>\n",
       "      <td>-0.430701</td>\n",
       "      <td>1.024038</td>\n",
       "      <td>0.272508</td>\n",
       "      <td>-1.80512</td>\n",
       "      <td>-0.40318</td>\n",
       "      <td>-0.094587</td>\n",
       "      <td>3.959254</td>\n",
       "      <td>-0.05397</td>\n",
       "      <td>-0.154326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.683541</td>\n",
       "      <td>1.052039</td>\n",
       "      <td>-0.458953</td>\n",
       "      <td>-0.560954</td>\n",
       "      <td>-0.722999</td>\n",
       "      <td>-0.222923</td>\n",
       "      <td>-0.082396</td>\n",
       "      <td>1.148246</td>\n",
       "      <td>-0.430701</td>\n",
       "      <td>1.024038</td>\n",
       "      <td>-0.304398</td>\n",
       "      <td>0.55398</td>\n",
       "      <td>-0.40318</td>\n",
       "      <td>-0.094587</td>\n",
       "      <td>-0.252573</td>\n",
       "      <td>-0.05397</td>\n",
       "      <td>-0.154326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.462970</td>\n",
       "      <td>-0.070720</td>\n",
       "      <td>-0.663161</td>\n",
       "      <td>-1.486552</td>\n",
       "      <td>-1.296515</td>\n",
       "      <td>-0.222923</td>\n",
       "      <td>-0.216920</td>\n",
       "      <td>-0.107023</td>\n",
       "      <td>-0.430701</td>\n",
       "      <td>1.024038</td>\n",
       "      <td>0.320853</td>\n",
       "      <td>-1.80512</td>\n",
       "      <td>2.48028</td>\n",
       "      <td>-0.094587</td>\n",
       "      <td>-0.252573</td>\n",
       "      <td>-0.05397</td>\n",
       "      <td>-0.154326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.462970</td>\n",
       "      <td>0.677786</td>\n",
       "      <td>-0.663161</td>\n",
       "      <td>-1.178020</td>\n",
       "      <td>-0.722999</td>\n",
       "      <td>-0.222923</td>\n",
       "      <td>-0.216920</td>\n",
       "      <td>0.395085</td>\n",
       "      <td>-0.430701</td>\n",
       "      <td>-0.976526</td>\n",
       "      <td>0.169977</td>\n",
       "      <td>0.55398</td>\n",
       "      <td>-0.40318</td>\n",
       "      <td>-0.094587</td>\n",
       "      <td>-0.252573</td>\n",
       "      <td>-0.05397</td>\n",
       "      <td>-0.154326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.683541</td>\n",
       "      <td>-1.193480</td>\n",
       "      <td>-1.207716</td>\n",
       "      <td>-0.252421</td>\n",
       "      <td>-0.722999</td>\n",
       "      <td>-0.222923</td>\n",
       "      <td>-0.149658</td>\n",
       "      <td>-0.107023</td>\n",
       "      <td>2.321798</td>\n",
       "      <td>-0.976526</td>\n",
       "      <td>1.698667</td>\n",
       "      <td>0.55398</td>\n",
       "      <td>-0.40318</td>\n",
       "      <td>-0.094587</td>\n",
       "      <td>-0.252573</td>\n",
       "      <td>-0.05397</td>\n",
       "      <td>-0.154326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mother_marital_status  mother_height  mother_weight_gain  \\\n",
       "0           0              -0.683541      -0.444973           -0.458953   \n",
       "1           1              -0.683541       1.052039           -0.458953   \n",
       "2           2               1.462970      -0.070720           -0.663161   \n",
       "3           3               1.462970       0.677786           -0.663161   \n",
       "4           5              -0.683541      -1.193480           -1.207716   \n",
       "\n",
       "   father_age  father_education  cigarettes_before_pregnancy  \\\n",
       "0   -0.252421          0.997547                    -0.222923   \n",
       "1   -0.560954         -0.722999                    -0.222923   \n",
       "2   -1.486552         -1.296515                    -0.222923   \n",
       "3   -1.178020         -0.722999                    -0.222923   \n",
       "4   -0.252421         -0.722999                    -0.222923   \n",
       "\n",
       "   prenatal_care_month  number_prenatal_visits  previous_cesarean  \\\n",
       "0            -0.216920                0.897192          -0.430701   \n",
       "1            -0.082396                1.148246          -0.430701   \n",
       "2            -0.216920               -0.107023          -0.430701   \n",
       "3            -0.216920                0.395085          -0.430701   \n",
       "4            -0.149658               -0.107023           2.321798   \n",
       "\n",
       "   newborn_gender  body_mass_index_to_delivery_weight  mother_race_white  \\\n",
       "0        1.024038                            0.272508           -1.80512   \n",
       "1        1.024038                           -0.304398            0.55398   \n",
       "2        1.024038                            0.320853           -1.80512   \n",
       "3       -0.976526                            0.169977            0.55398   \n",
       "4       -0.976526                            1.698667            0.55398   \n",
       "\n",
       "   mother_race_black  mother_race_aian  mother_race_asian  mother_race_nhopi  \\\n",
       "0           -0.40318         -0.094587           3.959254           -0.05397   \n",
       "1           -0.40318         -0.094587          -0.252573           -0.05397   \n",
       "2            2.48028         -0.094587          -0.252573           -0.05397   \n",
       "3           -0.40318         -0.094587          -0.252573           -0.05397   \n",
       "4           -0.40318         -0.094587          -0.252573           -0.05397   \n",
       "\n",
       "   mother_race_more_than_one  \n",
       "0                  -0.154326  \n",
       "1                  -0.154326  \n",
       "2                  -0.154326  \n",
       "3                  -0.154326  \n",
       "4                  -0.154326  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newborn_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "newborn_train = newborn_train.drop('Unnamed: 0', axis=1)\n",
    "newborn_test = newborn_test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algorithm Selection\n",
    "Now we move to choose the modeling techniques for regression. We decided to test following modeling techniques: Ordinary Least Squares, Elastic Net, Nearest Neighbors, Decision Tree, Support Vector Regression and then choose the technique that yield the best results. \n",
    "For every algorithm we will follow this steps: parameter tuning, create the model, train the model, test the model, iterate and improve\n",
    "\n",
    "Linear regression is a simple and commonly used algorithm for regression tasks.\n",
    "It assumes a linear relationship between the input features and the target variable.\n",
    "We can use linear regression to model the relationship between the features in the dataset and the newborn weight.\n",
    "\n",
    "### OLS\n",
    "Ordinary Least Squares aims to minimize the sum of squared residuals between the predicted values and the actual values of the target variable. OLS assumes that the relationship between the independent variables and the dependent variable is linear and that the errors follow a normal distribution with constant variance. The estimated coefficients obtained from OLS represent the best linear unbiased estimates of the true population parameters. OLS is widely used due to its simplicity and interpretability, but it can be sensitive to outliers and violations of its underlying assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1708062 entries, 0 to 1708061\n",
      "Data columns (total 18 columns):\n",
      " #   Column                              Dtype  \n",
      "---  ------                              -----  \n",
      " 0   mother_marital_status               float64\n",
      " 1   mother_height                       float64\n",
      " 2   mother_weight_gain                  float64\n",
      " 3   father_age                          float64\n",
      " 4   father_education                    float64\n",
      " 5   cigarettes_before_pregnancy         float64\n",
      " 6   prenatal_care_month                 float64\n",
      " 7   number_prenatal_visits              float64\n",
      " 8   previous_cesarean                   float64\n",
      " 9   newborn_gender                      float64\n",
      " 10  newborn_weight                      int64  \n",
      " 11  body_mass_index_to_delivery_weight  float64\n",
      " 12  mother_race_white                   float64\n",
      " 13  mother_race_black                   float64\n",
      " 14  mother_race_aian                    float64\n",
      " 15  mother_race_asian                   float64\n",
      " 16  mother_race_nhopi                   float64\n",
      " 17  mother_race_more_than_one           float64\n",
      "dtypes: float64(17), int64(1)\n",
      "memory usage: 234.6 MB\n"
     ]
    }
   ],
   "source": [
    "newborn_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split our training sample into two parts: validation and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    newborn_train.drop('newborn_weight', axis=1), newborn_train[['newborn_weight']], \n",
    "    test_size=0.25, random_state=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>newborn_weight</td>  <th>  R-squared:         </th>  <td>   0.088</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.088</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   7304.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Jun 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:55:34</td>     <th>  Log-Likelihood:    </th> <td>-9.9156e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1281046</td>     <th>  AIC:               </th>  <td>1.983e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>1281028</td>     <th>  BIC:               </th>  <td>1.983e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                              <td> 3282.5320</td> <td>    0.492</td> <td> 6678.514</td> <td> 0.000</td> <td> 3281.569</td> <td> 3283.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_marital_status</th>              <td>  -26.5009</td> <td>    0.746</td> <td>  -35.501</td> <td> 0.000</td> <td>  -27.964</td> <td>  -25.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_height</th>                      <td>   68.9507</td> <td>    0.699</td> <td>   98.680</td> <td> 0.000</td> <td>   67.581</td> <td>   70.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_weight_gain</th>                 <td>   81.6071</td> <td>    0.756</td> <td>  107.970</td> <td> 0.000</td> <td>   80.126</td> <td>   83.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>father_age</th>                         <td>   -0.3304</td> <td>    0.524</td> <td>   -0.630</td> <td> 0.529</td> <td>   -1.358</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>father_education</th>                   <td>   -4.2731</td> <td>    0.560</td> <td>   -7.626</td> <td> 0.000</td> <td>   -5.371</td> <td>   -3.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cigarettes_before_pregnancy</th>        <td>  -35.1309</td> <td>    0.500</td> <td>  -70.239</td> <td> 0.000</td> <td>  -36.111</td> <td>  -34.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prenatal_care_month</th>                <td>  -13.9129</td> <td>    0.494</td> <td>  -28.175</td> <td> 0.000</td> <td>  -14.881</td> <td>  -12.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_prenatal_visits</th>             <td>   64.6113</td> <td>    0.498</td> <td>  129.818</td> <td> 0.000</td> <td>   63.636</td> <td>   65.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_cesarean</th>                  <td>   19.0017</td> <td>    0.497</td> <td>   38.217</td> <td> 0.000</td> <td>   18.027</td> <td>   19.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newborn_gender</th>                     <td>  -56.9037</td> <td>    0.492</td> <td> -115.723</td> <td> 0.000</td> <td>  -57.867</td> <td>  -55.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body_mass_index_to_delivery_weight</th> <td>    3.5812</td> <td>    0.934</td> <td>    3.834</td> <td> 0.000</td> <td>    1.751</td> <td>    5.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_white</th>                  <td>-5.992e+12</td> <td> 1.37e+13</td> <td>   -0.438</td> <td> 0.661</td> <td>-3.28e+13</td> <td> 2.08e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_black</th>                  <td>  -4.9e+12</td> <td> 1.12e+13</td> <td>   -0.438</td> <td> 0.661</td> <td>-2.68e+13</td> <td>  1.7e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_aian</th>                   <td>-1.331e+12</td> <td> 3.04e+12</td> <td>   -0.438</td> <td> 0.661</td> <td>-7.28e+12</td> <td> 4.62e+12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_asian</th>                  <td>-3.354e+12</td> <td> 7.65e+12</td> <td>   -0.438</td> <td> 0.661</td> <td>-1.83e+13</td> <td> 1.16e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_nhopi</th>                  <td>-7.633e+11</td> <td> 1.74e+12</td> <td>   -0.438</td> <td> 0.661</td> <td>-4.18e+12</td> <td> 2.65e+12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_more_than_one</th>          <td>-2.129e+12</td> <td> 4.86e+12</td> <td>   -0.438</td> <td> 0.661</td> <td>-1.16e+13</td> <td> 7.39e+12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>195770.249</td> <th>  Durbin-Watson:     </th>  <td>   1.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>526117.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.841</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 5.651</td>   <th>  Cond. No.          </th>  <td>6.11e+13</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.62e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         newborn_weight   R-squared:                       0.088\n",
       "Model:                            OLS   Adj. R-squared:                  0.088\n",
       "Method:                 Least Squares   F-statistic:                     7304.\n",
       "Date:                Sun, 11 Jun 2023   Prob (F-statistic):               0.00\n",
       "Time:                        23:55:34   Log-Likelihood:            -9.9156e+06\n",
       "No. Observations:             1281046   AIC:                         1.983e+07\n",
       "Df Residuals:                 1281028   BIC:                         1.983e+07\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "const                               3282.5320      0.492   6678.514      0.000    3281.569    3283.495\n",
       "mother_marital_status                -26.5009      0.746    -35.501      0.000     -27.964     -25.038\n",
       "mother_height                         68.9507      0.699     98.680      0.000      67.581      70.320\n",
       "mother_weight_gain                    81.6071      0.756    107.970      0.000      80.126      83.089\n",
       "father_age                            -0.3304      0.524     -0.630      0.529      -1.358       0.697\n",
       "father_education                      -4.2731      0.560     -7.626      0.000      -5.371      -3.175\n",
       "cigarettes_before_pregnancy          -35.1309      0.500    -70.239      0.000     -36.111     -34.151\n",
       "prenatal_care_month                  -13.9129      0.494    -28.175      0.000     -14.881     -12.945\n",
       "number_prenatal_visits                64.6113      0.498    129.818      0.000      63.636      65.587\n",
       "previous_cesarean                     19.0017      0.497     38.217      0.000      18.027      19.976\n",
       "newborn_gender                       -56.9037      0.492   -115.723      0.000     -57.867     -55.940\n",
       "body_mass_index_to_delivery_weight     3.5812      0.934      3.834      0.000       1.751       5.412\n",
       "mother_race_white                  -5.992e+12   1.37e+13     -0.438      0.661   -3.28e+13    2.08e+13\n",
       "mother_race_black                    -4.9e+12   1.12e+13     -0.438      0.661   -2.68e+13     1.7e+13\n",
       "mother_race_aian                   -1.331e+12   3.04e+12     -0.438      0.661   -7.28e+12    4.62e+12\n",
       "mother_race_asian                  -3.354e+12   7.65e+12     -0.438      0.661   -1.83e+13    1.16e+13\n",
       "mother_race_nhopi                  -7.633e+11   1.74e+12     -0.438      0.661   -4.18e+12    2.65e+12\n",
       "mother_race_more_than_one          -2.129e+12   4.86e+12     -0.438      0.661   -1.16e+13    7.39e+12\n",
       "==============================================================================\n",
       "Omnibus:                   195770.249   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           526117.733\n",
       "Skew:                          -0.841   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.651   Cond. No.                     6.11e+13\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.62e-22. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add constant\n",
    "X1_train = sm.add_constant(X_train)\n",
    "\n",
    "# the OLS model\n",
    "ols_model = sm.OLS(y_train, X1_train)\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# print summary\n",
    "ols_results.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that father_age is statistically insignificant so we will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>newborn_weight</td>  <th>  R-squared:         </th>  <td>   0.088</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.088</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   7760.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Jun 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:55:37</td>     <th>  Log-Likelihood:    </th> <td>-9.9156e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1281046</td>     <th>  AIC:               </th>  <td>1.983e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>1281029</td>     <th>  BIC:               </th>  <td>1.983e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                              <td> 3282.5344</td> <td>    0.492</td> <td> 6677.150</td> <td> 0.000</td> <td> 3281.571</td> <td> 3283.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_marital_status</th>              <td>  -26.4585</td> <td>    0.736</td> <td>  -35.927</td> <td> 0.000</td> <td>  -27.902</td> <td>  -25.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_height</th>                      <td>   68.9302</td> <td>    0.698</td> <td>   98.748</td> <td> 0.000</td> <td>   67.562</td> <td>   70.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_weight_gain</th>                 <td>   81.6128</td> <td>    0.756</td> <td>  107.982</td> <td> 0.000</td> <td>   80.131</td> <td>   83.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>father_education</th>                   <td>   -4.3309</td> <td>    0.553</td> <td>   -7.834</td> <td> 0.000</td> <td>   -5.414</td> <td>   -3.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cigarettes_before_pregnancy</th>        <td>  -35.1361</td> <td>    0.500</td> <td>  -70.261</td> <td> 0.000</td> <td>  -36.116</td> <td>  -34.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prenatal_care_month</th>                <td>  -13.9158</td> <td>    0.494</td> <td>  -28.181</td> <td> 0.000</td> <td>  -14.884</td> <td>  -12.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_prenatal_visits</th>             <td>   64.6090</td> <td>    0.498</td> <td>  129.819</td> <td> 0.000</td> <td>   63.634</td> <td>   65.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_cesarean</th>                  <td>   18.9635</td> <td>    0.494</td> <td>   38.418</td> <td> 0.000</td> <td>   17.996</td> <td>   19.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newborn_gender</th>                     <td>  -56.9042</td> <td>    0.492</td> <td> -115.724</td> <td> 0.000</td> <td>  -57.868</td> <td>  -55.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body_mass_index_to_delivery_weight</th> <td>    3.5694</td> <td>    0.934</td> <td>    3.823</td> <td> 0.000</td> <td>    1.739</td> <td>    5.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_white</th>                  <td>-5.426e+12</td> <td> 1.37e+13</td> <td>   -0.396</td> <td> 0.692</td> <td>-3.23e+13</td> <td> 2.14e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_black</th>                  <td>-4.438e+12</td> <td> 1.12e+13</td> <td>   -0.396</td> <td> 0.692</td> <td>-2.64e+13</td> <td> 1.75e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_aian</th>                   <td>-1.206e+12</td> <td> 3.04e+12</td> <td>   -0.396</td> <td> 0.692</td> <td>-7.17e+12</td> <td> 4.76e+12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_asian</th>                  <td>-3.038e+12</td> <td> 7.67e+12</td> <td>   -0.396</td> <td> 0.692</td> <td>-1.81e+13</td> <td>  1.2e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_nhopi</th>                  <td>-6.913e+11</td> <td> 1.74e+12</td> <td>   -0.396</td> <td> 0.692</td> <td>-4.11e+12</td> <td> 2.73e+12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_more_than_one</th>          <td>-1.928e+12</td> <td> 4.87e+12</td> <td>   -0.396</td> <td> 0.692</td> <td>-1.15e+13</td> <td> 7.61e+12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>195832.367</td> <th>  Durbin-Watson:     </th>  <td>   1.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>526325.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.841</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 5.651</td>   <th>  Cond. No.          </th>  <td>6.09e+13</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.59e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         newborn_weight   R-squared:                       0.088\n",
       "Model:                            OLS   Adj. R-squared:                  0.088\n",
       "Method:                 Least Squares   F-statistic:                     7760.\n",
       "Date:                Sun, 11 Jun 2023   Prob (F-statistic):               0.00\n",
       "Time:                        23:55:37   Log-Likelihood:            -9.9156e+06\n",
       "No. Observations:             1281046   AIC:                         1.983e+07\n",
       "Df Residuals:                 1281029   BIC:                         1.983e+07\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "const                               3282.5344      0.492   6677.150      0.000    3281.571    3283.498\n",
       "mother_marital_status                -26.4585      0.736    -35.927      0.000     -27.902     -25.015\n",
       "mother_height                         68.9302      0.698     98.748      0.000      67.562      70.298\n",
       "mother_weight_gain                    81.6128      0.756    107.982      0.000      80.131      83.094\n",
       "father_education                      -4.3309      0.553     -7.834      0.000      -5.414      -3.247\n",
       "cigarettes_before_pregnancy          -35.1361      0.500    -70.261      0.000     -36.116     -34.156\n",
       "prenatal_care_month                  -13.9158      0.494    -28.181      0.000     -14.884     -12.948\n",
       "number_prenatal_visits                64.6090      0.498    129.819      0.000      63.634      65.584\n",
       "previous_cesarean                     18.9635      0.494     38.418      0.000      17.996      19.931\n",
       "newborn_gender                       -56.9042      0.492   -115.724      0.000     -57.868     -55.940\n",
       "body_mass_index_to_delivery_weight     3.5694      0.934      3.823      0.000       1.739       5.400\n",
       "mother_race_white                  -5.426e+12   1.37e+13     -0.396      0.692   -3.23e+13    2.14e+13\n",
       "mother_race_black                  -4.438e+12   1.12e+13     -0.396      0.692   -2.64e+13    1.75e+13\n",
       "mother_race_aian                   -1.206e+12   3.04e+12     -0.396      0.692   -7.17e+12    4.76e+12\n",
       "mother_race_asian                  -3.038e+12   7.67e+12     -0.396      0.692   -1.81e+13     1.2e+13\n",
       "mother_race_nhopi                  -6.913e+11   1.74e+12     -0.396      0.692   -4.11e+12    2.73e+12\n",
       "mother_race_more_than_one          -1.928e+12   4.87e+12     -0.396      0.692   -1.15e+13    7.61e+12\n",
       "==============================================================================\n",
       "Omnibus:                   195832.367   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           526325.993\n",
       "Skew:                          -0.841   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.651   Cond. No.                     6.09e+13\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.59e-22. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# independent variables\n",
    "X1_train = X1_train.drop('father_age', axis=1)\n",
    "\n",
    "# the OLS model\n",
    "ols_model = sm.OLS(y_train, X1_train)\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# print summary\n",
    "ols_results.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that also variables connected to race are insignificant so we continue removing them one by one using the method from general to specific. At first we will remove mother_race_more_than_one because it concerns the most broad spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>newborn_weight</td>  <th>  R-squared:         </th>  <td>   0.088</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.088</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   8278.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Jun 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:55:39</td>     <th>  Log-Likelihood:    </th> <td>-9.9156e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1281046</td>     <th>  AIC:               </th>  <td>1.983e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>1281030</td>     <th>  BIC:               </th>  <td>1.983e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                              <td> 3282.5301</td> <td>    0.491</td> <td> 6678.803</td> <td> 0.000</td> <td> 3281.567</td> <td> 3283.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_marital_status</th>              <td>  -26.6513</td> <td>    0.553</td> <td>  -48.209</td> <td> 0.000</td> <td>  -27.735</td> <td>  -25.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_height</th>                      <td>   68.9300</td> <td>    0.698</td> <td>   98.748</td> <td> 0.000</td> <td>   67.562</td> <td>   70.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_weight_gain</th>                 <td>   81.6119</td> <td>    0.756</td> <td>  107.982</td> <td> 0.000</td> <td>   80.131</td> <td>   83.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>father_education</th>                   <td>   -4.3291</td> <td>    0.553</td> <td>   -7.831</td> <td> 0.000</td> <td>   -5.413</td> <td>   -3.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cigarettes_before_pregnancy</th>        <td>  -35.1365</td> <td>    0.500</td> <td>  -70.262</td> <td> 0.000</td> <td>  -36.117</td> <td>  -34.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prenatal_care_month</th>                <td>  -13.9151</td> <td>    0.494</td> <td>  -28.180</td> <td> 0.000</td> <td>  -14.883</td> <td>  -12.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_prenatal_visits</th>             <td>   64.6085</td> <td>    0.498</td> <td>  129.818</td> <td> 0.000</td> <td>   63.633</td> <td>   65.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_cesarean</th>                  <td>   18.9623</td> <td>    0.494</td> <td>   38.417</td> <td> 0.000</td> <td>   17.995</td> <td>   19.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newborn_gender</th>                     <td>  -56.9039</td> <td>    0.492</td> <td> -115.724</td> <td> 0.000</td> <td>  -57.868</td> <td>  -55.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body_mass_index_to_delivery_weight</th> <td>    3.5697</td> <td>    0.934</td> <td>    3.823</td> <td> 0.000</td> <td>    1.740</td> <td>    5.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_white</th>                  <td>   22.4082</td> <td>    1.390</td> <td>   16.117</td> <td> 0.000</td> <td>   19.683</td> <td>   25.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_black</th>                  <td>  -45.6315</td> <td>    1.210</td> <td>  -37.714</td> <td> 0.000</td> <td>  -48.003</td> <td>  -43.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_aian</th>                   <td>   10.5288</td> <td>    0.576</td> <td>   18.270</td> <td> 0.000</td> <td>    9.399</td> <td>   11.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_asian</th>                  <td>  -17.2011</td> <td>    0.912</td> <td>  -18.867</td> <td> 0.000</td> <td>  -18.988</td> <td>  -15.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mother_race_nhopi</th>                  <td>    4.1802</td> <td>    0.525</td> <td>    7.960</td> <td> 0.000</td> <td>    3.151</td> <td>    5.210</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>195628.080</td> <th>  Durbin-Watson:     </th>  <td>   1.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>525552.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.841</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 5.649</td>   <th>  Cond. No.          </th>  <td>    6.01</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         newborn_weight   R-squared:                       0.088\n",
       "Model:                            OLS   Adj. R-squared:                  0.088\n",
       "Method:                 Least Squares   F-statistic:                     8278.\n",
       "Date:                Sun, 11 Jun 2023   Prob (F-statistic):               0.00\n",
       "Time:                        23:55:39   Log-Likelihood:            -9.9156e+06\n",
       "No. Observations:             1281046   AIC:                         1.983e+07\n",
       "Df Residuals:                 1281030   BIC:                         1.983e+07\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "const                               3282.5301      0.491   6678.803      0.000    3281.567    3283.493\n",
       "mother_marital_status                -26.6513      0.553    -48.209      0.000     -27.735     -25.568\n",
       "mother_height                         68.9300      0.698     98.748      0.000      67.562      70.298\n",
       "mother_weight_gain                    81.6119      0.756    107.982      0.000      80.131      83.093\n",
       "father_education                      -4.3291      0.553     -7.831      0.000      -5.413      -3.246\n",
       "cigarettes_before_pregnancy          -35.1365      0.500    -70.262      0.000     -36.117     -34.156\n",
       "prenatal_care_month                  -13.9151      0.494    -28.180      0.000     -14.883     -12.947\n",
       "number_prenatal_visits                64.6085      0.498    129.818      0.000      63.633      65.584\n",
       "previous_cesarean                     18.9623      0.494     38.417      0.000      17.995      19.930\n",
       "newborn_gender                       -56.9039      0.492   -115.724      0.000     -57.868     -55.940\n",
       "body_mass_index_to_delivery_weight     3.5697      0.934      3.823      0.000       1.740       5.400\n",
       "mother_race_white                     22.4082      1.390     16.117      0.000      19.683      25.133\n",
       "mother_race_black                    -45.6315      1.210    -37.714      0.000     -48.003     -43.260\n",
       "mother_race_aian                      10.5288      0.576     18.270      0.000       9.399      11.658\n",
       "mother_race_asian                    -17.2011      0.912    -18.867      0.000     -18.988     -15.414\n",
       "mother_race_nhopi                      4.1802      0.525      7.960      0.000       3.151       5.210\n",
       "==============================================================================\n",
       "Omnibus:                   195628.080   Durbin-Watson:                   1.996\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           525552.786\n",
       "Skew:                          -0.841   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.649   Cond. No.                         6.01\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# independent variables\n",
    "X1_train = X1_train.drop('mother_race_more_than_one', axis=1)\n",
    "\n",
    "# add constant\n",
    "X1_train = sm.add_constant(X1_train)\n",
    "\n",
    "# the OLS model\n",
    "ols_model = sm.OLS(y_train, X1_train)\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# print summary\n",
    "ols_results.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all variables are significant so model is ready and we can interpret the results. R squared is 0.088 so our moedl explained 8.8% of the variation of target variable which is a bit small. All variables are jointly significant because p-value is 0 so we reject null hypothesis. Now we will perform tests to check other assumptions of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESET Test:\n",
      "Test Statistic: 699.2044776825902\n",
      "p-value: 3.1987016899408065e-304\n",
      "\n",
      "Breusch-Pagan Test:\n",
      "Test Statistic: 16002.504230868584\n",
      "p-value: 0.0\n",
      "\n",
      "Breusch-Godfrey Test:\n",
      "Test Statistic: 5.584146263252677\n",
      "p-value: 0.018123765307410385\n",
      "\n",
      "Jarque-Bera Test:\n",
      "Test Statistic: 525552.7862625656\n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# RESET Test\n",
    "fitted_vals = ols_results.fittedvalues\n",
    "reset_model = sm.OLS(ols_results.resid, sm.add_constant(np.column_stack((fitted_vals, fitted_vals**2))))\n",
    "reset_results = reset_model.fit()\n",
    "reset_test_statistic = reset_results.fvalue\n",
    "reset_p_value = reset_results.f_pvalue\n",
    "\n",
    "# Breusch-Pagan Test\n",
    "bp_test_statistic, bp_p_value, _, _ = het_breuschpagan(ols_results.resid, X1_train)\n",
    "\n",
    "# Breusch-Godfrey Test\n",
    "bg_test_statistic, bg_p_value, _, _ = acorr_breusch_godfrey(ols_results, nlags=1)  # Specify the number of lags\n",
    "\n",
    "# Jarque-Bera Test\n",
    "jb_test_statistic, jb_p_value, _, _ = jarque_bera(ols_results.resid)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"RESET Test:\")\n",
    "print(\"Test Statistic:\", reset_test_statistic)\n",
    "print(\"p-value:\", reset_p_value)\n",
    "\n",
    "print(\"\\nBreusch-Pagan Test:\")\n",
    "print(\"Test Statistic:\", bp_test_statistic)\n",
    "print(\"p-value:\", bp_p_value)\n",
    "\n",
    "print(\"\\nBreusch-Godfrey Test:\")\n",
    "print(\"Test Statistic:\", bg_test_statistic)\n",
    "print(\"p-value:\", bg_p_value)\n",
    "\n",
    "print(\"\\nJarque-Bera Test:\")\n",
    "print(\"Test Statistic:\", jb_test_statistic)\n",
    "print(\"p-value:\", jb_p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Breusch-Pagan, Breusch-Godfrey and Jarque-Bera tests p-values are 0 (or close to zero) so we rejest null hypothesis, so we have heteroscedasticity, there is autocorrelation and residuals aren't normally distributed. Only p-value for RESET Test is higher than significance level so we conclude that model have linear form.\n",
    "\n",
    "According to really small rsquared and that model does not pass many tests, he is not the best choice for prediting newborn weight.\n",
    "\n",
    "Now we will train our model using our training set X_train and y_train."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the model performance by comparing its predictions with the actual true values in y_valid using the MAPE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_valid = newborn_train['newborn_weight']\n",
    "X1_valid = newborn_train[['mother_marital_status', 'mother_height', 'mother_weight_gain', 'father_education', 'cigarettes_before_pregnancy', 'prenatal_care_month', 'number_prenatal_visits', 'previous_cesarean', 'newborn_gender', 'body_mass_index_to_delivery_weight', 'mother_race_white', 'mother_race_black', 'mother_race_aian', 'mother_race_asian', 'mother_race_nhopi']]\n",
    "X1_valid = sm.add_constant(X1_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE = 0.15791843365139757\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable \n",
    "y1_pred_v = ols_results.predict(X1_valid)\n",
    "\n",
    "# Calculate the mean absolute percentage error\n",
    "ols_mape = mean_absolute_percentage_error(y1_valid, y1_pred_v)\n",
    "print(\"MAPE =\", ols_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that, on average, the predictions from the model have an absolute percentage error of around 15.79%.\n",
    "\n",
    "The MAPE provides a measure of the accuracy of the predictions relative to the actual values. A lower MAPE indicates better prediction performance. In this case, a MAPE of 0.1579 suggests that the linear regression model has reasonably good predictive power for the target variable in the test set.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "\n",
    "Elastic Net is a combination of Ridge regression and Lasso regression. Like Ridge regression, it adds a penalty term to the linear regression objective function. However, in Elastic Net, the penalty term consists of a combination of the L1 norm (sum of the absolute values of the coefficients) and the L2 norm (sum of the squared values of the coefficients), weighted by two regularization parameters: alpha and l1_ratio. The alpha parameter controls the overall strength of regularization, while the l1_ratio determines the balance between L1 and L2 regularization. Elastic Net can be useful when there are many correlated features and the model needs to perform feature selection and regularization simultaneously. \n",
    "\n",
    "We will use scikit-learn's GridSearchCV to perform a grid search with cross-validation for hyperparameter tuning of the ElasticNet model. The parameter_space dictionary defines the range of values to explore for each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'alpha': 1, 'fit_intercept': True, 'l1_ratio': 1}\n"
     ]
    }
   ],
   "source": [
    "X2_train=X_train\n",
    "y2_train=y_train\n",
    "\n",
    "parameter_space = {\n",
    "    \"alpha\": [1, 10, 100, 200, 300],\n",
    "    \"l1_ratio\": [0.5, 1],\n",
    "    \"fit_intercept\": [True, False],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(ElasticNet(random_state=3), parameter_space, \n",
    "                   n_jobs=4, cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "clf.fit(X2_train, y2_train)\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n_jobs parameter is set to 3, indicating that the grid search will use three parallel jobs for training and evaluating the models. This means that three separate processes will be spawned to perform the computations concurrently, utilizing the available CPU cores. \n",
    "\n",
    "The cv parameter is set to 3, indicating that a 3-fold cross-validation strategy will be used during the grid search. This means the data will be split into three subsets, and the model will be trained and evaluated three times, each time using a different subset as the validation set. The performance metric specified by the scoring parameter (neg_mean_absolute_error in this case) will be used to evaluate the models and select the best hyperparameters.\n",
    "\n",
    "After the grid search is complete, the best hyperparameters are printed using clf.best_params_. These are the hyperparameters that yielded the best performance according to the chosen scoring metric.\n",
    "\n",
    "The alpha parameter controls the regularization strength of the model. A smaller value indicates weaker regularization. In this case, the best value found is 1.\n",
    "\n",
    "The fit_intercept parameter determines whether or not an intercept term should be included in the model. The best value found is True, indicating that including an intercept term improves the model's performance.\n",
    "\n",
    "The l1_ratio parameter indicating a stronger preference for L1 (Lasso) regularization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the ElasticNet\n",
    "elasticNet_model = ElasticNet(random_state=3, **clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1, l1_ratio=1, random_state=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model \n",
    "elasticNet_model.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE = 0.1581801353160445\n"
     ]
    }
   ],
   "source": [
    "X2_valid=X_valid\n",
    "y2_valid=y_valid\n",
    "\n",
    "# Predict the target variable\n",
    "y2_pred_v = elasticNet_model.predict(X2_valid)\n",
    "\n",
    "# Calculate the mean absolute percentage error\n",
    "elasticNet_mape = mean_absolute_percentage_error(y2_valid, y2_pred_v)\n",
    "print(\"MAPE =\", elasticNet_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that, on average, the predictions from the model have an absolute percentage error of around 15.81%.\n",
    "\n",
    "### Nearest Neighbors\n",
    "\n",
    "We will apply k-Nearest Neighbors (k-NN) which is a non-parametric algorithm that makes predictions based on the similarity of data points in the feature space.\n",
    "\n",
    "We will use parameter_space dictionary to define the hyperparameter options for the KNN regression model, including n_neighbors (number of neighbors to consider), weights (weighting scheme for neighbors), algorithm (algorithm used to compute nearest neighbors), and leaf_size (leaf size for tree-based algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train=X_train\n",
    "y3_train=y_train\n",
    "X3_valid=X_valid\n",
    "y3_valid=y_valid\n",
    "\n",
    "# Define the parameter space\n",
    "parameter_space = {\n",
    "    \"n_neighbors\": np.arange(3, 11),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"leaf_size\": [1, 2, 10, 20, 50]\n",
    "}\n",
    "\n",
    "# Perform randomized search using KNeighborsRegressor\n",
    "clf = RandomizedSearchCV(KNeighborsRegressor(), parameter_space, cv=3, \n",
    "                         scoring=\"neg_mean_absolute_error\", n_jobs=3)\n",
    "\n",
    "clf.fit(X3_train, y3_train)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(**clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable\n",
    "y3_pred_v = knn_model.predict(X3_valid)\n",
    "\n",
    "# Calculate the mean absolute percentage error\n",
    "knn_mape = mean_absolute_percentage_error(y3_valid, y3_pred_v)\n",
    "print(\"MAPE =\", knn_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "To perform DT (Decision tree) we will use DecisionTreeRegressor class from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train = X_train\n",
    "y4_train = y_train\n",
    "X4_valid = X_valid\n",
    "y4_valid = y_valid\n",
    "\n",
    "parameter_space = {\n",
    "    \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "    \"min_samples_split\": np.arange(3, 21),\n",
    "    \"min_samples_leaf\": np.arange(3, 21),\n",
    "    \"max_features\": np.arange(5, X4_train.shape[1] + 1),\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(DecisionTreeRegressor(random_state=3), parameter_space, \n",
    "                         cv=3, scoring=\"neg_mean_absolute_error\", n_jobs=4)\n",
    "\n",
    "clf.fit(X4_train, y4_train)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor(**clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable\n",
    "y4_pred_v = dt_model.predict(X4_valid)\n",
    "\n",
    "# Calculate the mean absolute percentage error\n",
    "dt_mape = mean_absolute_percentage_error(y4_valid, y4_pred_v)\n",
    "print(\"MAPE =\", dt_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression\n",
    "\n",
    "Support Vector Regression (SVR) is a variant of Support Vector Machines (SVM) that can be used for regression tasks. SVR aims to find a hyperplane that best fits the training data while minimizing the margin violations.\n",
    "\n",
    "We will search for the best model parameters using GridSearchCV(). Kernel specifies the kernel type, degree - the degree of the polynomial kernel, poly and gamma - the kernel coefficient for rbf, poly, sigmoid, coef0 - is independent term in kernel function and C is the penalty parameter of the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5_train=X_train\n",
    "y5_train=y_train\n",
    "X5_valid=X_valid\n",
    "y5_valid=y_valid\n",
    "\n",
    "parameter_space = \\\n",
    "    {\n",
    "        \"kernel\": [\"poly\", \"linear\", \"rbf\", \"sigmoid\"],\n",
    "        \"degree\": [3, 5],\n",
    "        \"coef0\": [0, 3, 7],\n",
    "        \"gamma\":[1e-3, 1e-1, 1/X5_train.shape[1]],\n",
    "        \"C\": [1, 10, 100],\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(SVR(), parameter_space, cv=3, n_jobs=4,\n",
    "                   scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "clf.fit(X5_train, y5_train)\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(**clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable\n",
    "y5_pred_v = svr_model.predict(X5_valid)\n",
    "\n",
    "# Calculate the mean absolute percentage error\n",
    "svr_mape = mean_absolute_percentage_error(y5_valid, y5_pred_v)\n",
    "print(\"MAPE =\", svr_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6_train=X_train\n",
    "y6_train=y_train\n",
    "X6_valid=X_valid\n",
    "y6_valid=y_valid\n",
    "\n",
    "parameter_space = \\\n",
    "    {\n",
    "        \"n_estimators\": [10, 100, 300, 600],\n",
    "        \"criterion\": [\"mse\", \"mae\"],\n",
    "        \"max_depth\": [7, 50, 254],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 5],\n",
    "        \"max_features\": [19, 100, X6_train.shape[1]],\n",
    "        \"bootstrap\": [True, False],\n",
    "    }\n",
    "\n",
    "clf = RandomizedSearchCV(RandomForestRegressor(random_state=3), \n",
    "                         parameter_space, cv=3, n_jobs=4,\n",
    "                         scoring=\"neg_mean_absolute_error\", \n",
    "                         n_iter=10, random_state=3)\n",
    "\n",
    "clf.fit(X6_train, y6_train)\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(**clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X6_train, y6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6_pred_v = rf_model.predict(X6_valid)\n",
    "rf_mape = mean_absolute_percentage_error(y6_valid, y6_pred_v)\n",
    "print(\"MAPE =\", rf_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X7_train=X_train\n",
    "y7_train=y_train\n",
    "X7_valid=X_valid\n",
    "y7_valid=y_valid\n",
    "\n",
    "parameter_space = \\\n",
    "    {\n",
    "        \"max_depth\": [4, 5, 6],\n",
    "        \"learning_rate\": [0.005, 0.009, 0.01],\n",
    "        \"n_estimators\": [700, 1000, 2500],\n",
    "        \"booster\": [\"gbtree\",],\n",
    "        \"gamma\": [7, 25, 100],\n",
    "        \"subsample\": [0.3, 0.6],\n",
    "        \"colsample_bytree\": [0.5, 0.7],\n",
    "        \"colsample_bylevel\": [0.5, 0.7,],\n",
    "        \"reg_alpha\": [1, 10, 33],\n",
    "        \"reg_lambda\": [1, 3, 10],\n",
    "    }\n",
    "\n",
    "clf = RandomizedSearchCV(XGBRegressor(random_state=3), \n",
    "                         parameter_space, cv=3, n_jobs=4,\n",
    "                         scoring=\"neg_mean_absolute_error\", \n",
    "                         random_state=3, n_iter=10)\n",
    "\n",
    "clf.fit(X7_train, y7_train)\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(**clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X7_train, y7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y7_pred_v = xgb_model.predict(X7_valid)\n",
    "xgb_mape = mean_absolute_percentage_error(y7_valid, y7_pred_v)\n",
    "print(\"MAPE =\", xgb_mape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We created five models and for every model we calculated MAPE. We are searching for the smallest value of MAPE. So we will choose the model to predict for the model with the smallest MAPE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
